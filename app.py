import streamlit as st

import pandas as pd

import numpy as np

from datetime import datetime, time

import io

import math

import re



# ==========================================

# 1. å…¨åŸŸé…ç½®

# ==========================================

SYSTEM_VERSION = "v23.1 (Fix: Multi-Gap Filling & Strict Setup Display)"



# ç·šå¤–è³‡æº

OFFLINE_CONFIG_MAP = {

    "è¶…éŸ³æ³¢": ("ç·šå¤–-è¶…éŸ³æ³¢ç†”æ¥", 1), 

    "LS": ("ç·šå¤–-çµ„è£å‰LS", 2),

    "é›·å°„": ("ç·šå¤–-çµ„è£å‰LS", 2),

    "PT": ("ç·šå¤–-PT", 1),

    "PKM": ("ç·šå¤–-ç·šé‚Šçµ„è£", 2),

    "è£é…": ("ç·šå¤–-ç·šé‚Šçµ„è£", 2),

    "çµ„è£": ("ç·šå¤–-ç·šé‚Šçµ„è£", 2),

    "AS": ("ç·šå¤–-ç·šé‚Šçµ„è£", 2)

}

OFFLINE_DEFAULTS = list(OFFLINE_CONFIG_MAP.keys())



def get_base_model(product_id):

    if pd.isna(product_id): return ""

    s = str(product_id).strip().split('/')[0].strip()

    parts = s.split('-')

    if len(parts) >= 2 and parts[0].upper() == 'N':

        return f"{parts[0]}-{parts[1]}"

    return s



def parse_time_to_mins(time_str):

    try:

        t = datetime.strptime(time_str, "%H:%M")

        return t.hour * 60 + t.minute

    except: return 480 



def create_line_mask(start_str, end_str, days=14):

    total_minutes = days * 24 * 60

    mask = np.zeros(total_minutes, dtype=bool)

    start_min = parse_time_to_mins(start_str)

    end_min = parse_time_to_mins(end_str)

    breaks = [(600, 605), (720, 780), (900, 905), (1020, 1050)]

    for day in range(days):

        offset = day * 1440

        if end_min > start_min:

            mask[offset + start_min : offset + end_min] = True

            for b_s, b_e in breaks:

                mask[offset + b_s : offset + b_e] = False

    return mask



def format_time_str(minute_idx):

    d = (minute_idx // 1440) + 1

    m = minute_idx % 1440

    return f"D{d} {m//60:02d}:{m%60:02d}"



def extract_line_num(val):

    match = re.search(r'LINE(\d+)', str(val).upper().replace(' ', ''))

    return int(match.group(1)) if match else 0



def get_sequence(val):

    try:

        match = re.search(r'(\d+)', str(val))

        if match: return int(match.group(1))

        return 0 

    except: return 0



# ==========================================

# 2. è¦å‰‡å¼•æ“

# ==========================================

class RuleEngine:

    def __init__(self, df_rules):

        self.rules = []          

        self.fixed_lines = set() 

        self.product_binding = {} 

        self.parse_rules(df_rules)



    def parse_rules(self, df):

        if df is None: return

        df.columns = df.columns.astype(str).str.replace(r'[\n\r\s]', '', regex=True)

        

        c_type = next((c for c in df.columns if 'å½ˆæ€§' in c or 'å›ºå®š' in c), None)

        c_line = next((c for c in df.columns if 'ç·šåˆ¥' in c and 'å½ˆæ€§' not in c), None)

        c_prod = next((c for c in df.columns if 'ç”¢å“' in c), None)

        c_proc = next((c for c in df.columns if 'é ˜æ–™' in c or 'è£½ç¨‹' in c), None)



        if not (c_type and c_line and c_prod): return



        for _, row in df.iterrows():

            l_type = str(row[c_type]).strip()

            l_name = str(row[c_line]).strip()

            p_pat = str(row[c_prod]).strip().replace('*', '') 

            proc = str(row[c_proc]).strip() if c_proc and not pd.isna(row[c_proc]) else ""

            

            l_idx = extract_line_num(l_name) - 4

            if l_idx < 0: continue



            if 'å›ºå®š' in l_type:

                self.fixed_lines.add(l_idx)

            

            if p_pat:

                if not proc or proc in ['å·¥å–®ç™¼æ–™', 'nan', '']:

                    self.product_binding[p_pat] = l_idx



            self.rules.append({

                'line_idx': l_idx, 'pattern': p_pat, 'process': proc, 'type': l_type

            })



    def get_assignment(self, product_id, process_type):

        for r in self.rules:

            if r['process'] and r['process'] not in ['å·¥å–®ç™¼æ–™', 'nan', '']:

                if r['pattern'] in str(product_id) and r['process'] in str(process_type):

                    return r['line_idx']

        return None



    def get_product_binding(self, product_id):

        for pat, l_idx in self.product_binding.items():

            if pat in str(product_id): return l_idx

        return None



    def can_line_accept_product(self, line_idx, product_id):

        # 1. å›ºå®šç·šæ½”ç™– (åªæ¥ç™½åå–®)

        if line_idx in self.fixed_lines:

            for r in self.rules:

                if r['line_idx'] == line_idx and r['pattern'] in str(product_id):

                    return True

            return False 

        

        # 2. å½ˆæ€§ç·š (ä¸æ¶å›ºå®šç·šçš„å–®ï¼Œé™¤éè¦å‰‡å…è¨±)

        for pat, bound_line in self.product_binding.items():

            if pat in str(product_id):

                if line_idx != bound_line: return False

        return True 



# ==========================================

# 3. è³‡æ–™è®€å–

# ==========================================

def load_and_clean_data(uploaded_file):

    try:

        xls = pd.read_excel(uploaded_file, sheet_name=None)

        df_ord = next((df for k,df in xls.items() if 'å·¥å–®' in df.columns or 'ç”¢å“' in str(df.columns)), None)

        df_rule = next((df for k,df in xls.items() if 'ç·šåˆ¥' in str(df.columns) or 'å½ˆæ€§' in str(df.columns)), None)

        

        if df_ord is None: return None, None, "ç¼ºå°‘å·¥å–®è³‡æ–™è¡¨"

        if df_rule is None: return None, None, "ç¼ºå°‘è¦å‰‡è³‡æ–™è¡¨"

        

        engine = RuleEngine(df_rule)

        df = df_ord.copy()

        df.columns = df.columns.astype(str).str.replace(r'[\n\s]', '', regex=True)

        col_map = {}

        for c in df.columns:

            if 'å·¥å–®' in c: col_map[c] = 'Order_ID'

            elif 'ç”¢å“' in c: col_map[c] = 'Product_ID'

            elif 'é å®š' in c: col_map[c] = 'Qty' 

            elif 'äººæ•¸' in c: col_map[c] = 'Manpower_Req' 

            elif 'å·¥æ™‚' in c: col_map[c] = 'Total_Man_Minutes' 

            elif 'é …æ¬¡' in c: col_map[c] = 'Priority'

            elif 'é ˜æ–™' in c: col_map[c] = 'Process_Type'

            elif 'å‚™è¨»' in c: col_map[c] = 'Remarks'

            elif 'æ€¥å–®' in c: col_map[c] = 'Rush_Col'

            elif 'æŒ‡å®š' in c: col_map[c] = 'Line_Col'

        df = df.rename(columns=col_map)

        

        for c in ['Qty', 'Manpower_Req', 'Total_Man_Minutes']:

            if c in df.columns:

                df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='coerce').fillna(0)

            else: df[c] = 0

            

        df = df[df['Qty'] > 0]

        df['Base_Model'] = df['Product_ID'].apply(get_base_model)

        

        def classify_row(row):

            prod = str(row['Product_ID'])

            proc = str(row['Process_Type'])

            assigned_line = engine.get_assignment(prod, proc)

            if assigned_line is not None: return False, assigned_line + 4, "Online", 0

            

            is_offline_kw = False

            offline_info = ("", 0)

            for kw, (gname, limit) in OFFLINE_CONFIG_MAP.items():

                if kw in proc:

                    is_offline_kw = True

                    offline_info = (gname, limit)

                    break

            if is_offline_kw: return True, 0, offline_info[0], offline_info[1]



            orig_target = extract_line_num(row.get('Line_Col', ''))

            if orig_target == 0: orig_target = extract_line_num(row.get('Remarks', ''))

            if orig_target == 0:

                bound_line = engine.get_product_binding(prod)

                if bound_line is not None: orig_target = bound_line + 4

            

            return False, orig_target, "Online", 0



        temp = df.apply(classify_row, axis=1)

        df['Is_Offline'] = temp.apply(lambda x: x[0])

        df['Target_Line'] = temp.apply(lambda x: x[1])

        df['Process_Category'] = temp.apply(lambda x: x[2])

        df['Concurrency_Limit'] = temp.apply(lambda x: x[3])



        if 'Rush_Col' not in df.columns: df['Rush_Col'] = ''

        df['Is_Rush'] = df['Rush_Col'].astype(str).str.contains('æ€¥å–®', na=False) | df['Remarks'].astype(str).str.contains('æ€¥å–®', na=False)

        df['Sequence'] = df['Remarks'].apply(get_sequence)



        return df, engine, None

    except Exception as e: return None, None, str(e)



# ==========================================

# 4. å ±è¡¨è¨ˆç®—

# ==========================================

def analyze_idle_manpower(timeline, masks, total_mp, max_min):

    global_mask = np.zeros(max_min, dtype=bool)

    for m in masks:

        l = min(len(m), max_min)

        global_mask[:l] |= m[:l]

    records = []

    curr_excess, start_t = -1, -1

    for t in range(max_min):

        if global_mask[t]:

            used = timeline[t]

            excess = total_mp - used

            if excess != curr_excess:

                if curr_excess > 0 and start_t != -1:

                    records.append({'é–‹å§‹æ™‚é–“': format_time_str(start_t), 'çµæŸæ™‚é–“': format_time_str(t), 'æŒçºŒåˆ†é˜': t-start_t, 'é–’ç½®(å¤šé¤˜)äººåŠ›': curr_excess})

                curr_excess, start_t = excess, t

        else:

            if curr_excess > 0 and start_t != -1:

                records.append({'é–‹å§‹æ™‚é–“': format_time_str(start_t), 'çµæŸæ™‚é–“': format_time_str(t), 'æŒçºŒåˆ†é˜': t-start_t, 'é–’ç½®(å¤šé¤˜)äººåŠ›': curr_excess})

            curr_excess, start_t = -1, -1

    return pd.DataFrame(records)



def calculate_daily_efficiency(timeline, masks, total_mp, results, days):

    recs = []

    for d in range(days):

        s, e = d*1440, (d+1)*1440

        std = np.sum(masks[0][s:e])

        used = np.sum(timeline[s:e])

        cap = total_mp * std

        eff = (used/cap*100) if cap > 0 else 0

        qty = sum(r['æ•¸é‡'] for r in results if r['ç‹€æ…‹']=='OK' and s <= r['æ’åºç”¨'] < e)

        sug_mp = math.ceil(used / (std * 0.95)) if std > 0 else 0

        diff = sug_mp - total_mp

        sug_str = f"å¢ {diff}" if diff > 0 else f"æ¸› {abs(diff)}"

        recs.append({'æ—¥æœŸ': f'D{d+1}', 'ç•¶æ—¥æ¨™æº–å·¥æ™‚(åˆ†)': std, 'ç¾æœ‰äººåŠ›': total_mp, 'å»ºè­°äººåŠ›(95%æ•ˆ)': sug_mp, 'èª¿åº¦å»ºè­°': sug_str, 'å¯¦éš›ç”¢å‡ºäººæ™‚': used, 'ç¸½ç”¢å‡ºæ•¸': int(qty), 'å…¨å» æ•ˆç‡(%)': round(eff, 2)})

    return pd.DataFrame(recs)



def calculate_line_utilization(matrix, masks, lines, days):

    recs = []

    for d in range(days):

        s, e = d*1440, (d+1)*1440

        row = {'æ—¥æœŸ': f'D{d+1}'}

        for i in range(lines):

            avail = np.sum(masks[i][s:e])

            busy = np.sum(matrix[i][s:e] & masks[i][s:e])

            row[f'Line {i+4} (%)'] = round(busy/avail*100, 1) if avail > 0 else 0

        recs.append(row)

    return pd.DataFrame(recs)



# ==========================================

# 5. æ’ç¨‹é‹ç®—å€ (Multi-Task Gap Filling + Strict Setup)

# ==========================================

def run_scheduler(df, engine, total_manpower, total_lines, std_changeover, similar_changeover, line_settings, offline_settings):

    MAX_MINUTES = 14 * 24 * 60 

    

    line_masks = []

    line_cumsums = []

    for setting in line_settings:

        m = create_line_mask(setting["start"], setting["end"], 14)

        line_masks.append(m)

        line_cumsums.append(np.cumsum(m))

    line_free_time = [parse_time_to_mins(setting["start"]) for setting in line_settings]

    line_last_model = {i: None for i in range(total_lines)}

    

    offline_mask = create_line_mask(offline_settings["start"], offline_settings["end"], 14)

    offline_cumsum = np.cumsum(offline_mask)

    offline_resource_usage = {} 

    

    timeline_manpower = np.zeros(MAX_MINUTES, dtype=int)

    line_usage_matrix = np.zeros((total_lines, MAX_MINUTES), dtype=bool)

    

    order_finish_times = {} 

    results = []



    rush_ids = df[df['Is_Rush']]['Order_ID'].unique()

    df['Order_Is_Rush'] = df['Order_ID'].isin(rush_ids)

    

    # å»ºç«‹ ID èˆ‡åˆ†æ± 

    all_tasks = df.to_dict('records')

    for i, t in enumerate(all_tasks): t['Pool_ID'] = i

    

    pool_rush = [t for t in all_tasks if t['Order_Is_Rush']]

    pool_fixed = []

    pool_normal = []

    

    for t in all_tasks:

        if t['Order_Is_Rush']: continue

        

        is_fixed = False

        if t['Target_Line'] > 0 and (t['Target_Line']-4) in engine.fixed_lines:

            is_fixed = True

        elif t['Target_Line'] == 0:

            bound = engine.get_product_binding(t['Base_Model'])

            if bound is not None and bound in engine.fixed_lines:

                is_fixed = True

        

        if is_fixed: pool_fixed.append(t)

        else: pool_normal.append(t)



    # æ’åº

    pool_rush.sort(key=lambda x: (x['Sequence'], x['Priority']))

    pool_fixed.sort(key=lambda x: (x['Target_Line'], x['Sequence'], x['Priority'])) 

    pool_normal.sort(key=lambda x: (x['Sequence'], x['Priority']))



    # ---------------- æ ¸å¿ƒå‡½æ•¸ ----------------

    def check_line_permission(l_idx, base_model, has_target_line, target_line_val):

        if has_target_line:

            return l_idx == (target_line_val - 4)

        return engine.can_line_accept_product(l_idx, base_model)



    def get_setup(l_idx, model, start_time):

        if line_last_model[l_idx] is None: return 0

        curr_day = start_time // 1440

        prev_finish = line_free_time[l_idx] 

        if (curr_day > (prev_finish // 1440)): return 0 

        return similar_changeover if line_last_model[l_idx] == model else std_changeover



    def find_earliest_slot(task, l_idx, min_start_time):

        manpower = int(task['Manpower_Req'])

        prod_duration = int(np.ceil(float(task['Total_Man_Minutes']) / manpower)) if manpower > 0 else 0

        

        if task['Is_Offline']:

            t_search = min_start_time

            mask = offline_mask

            cumsum = offline_cumsum

            res_group = task['Process_Category']

            res_limit = task['Concurrency_Limit']

            if res_group not in offline_resource_usage: 

                offline_resource_usage[res_group] = np.zeros(MAX_MINUTES, dtype=int)

        else:

            t_search = max(line_free_time[l_idx], min_start_time)

            mask = line_masks[l_idx]

            cumsum = line_cumsums[l_idx]



        while t_search < MAX_MINUTES - prod_duration: 

            if not mask[t_search]:

                t_search += 1

                continue

            

            this_setup = 0

            if not task['Is_Offline']:

                this_setup = get_setup(l_idx, task['Base_Model'], t_search)

            

            total_need = this_setup + prod_duration

            s_val = cumsum[t_search]

            t_val = s_val + total_need

            if t_val > cumsum[-1]: return None

            t_end = np.searchsorted(cumsum, t_val)

            

            if np.any(mask[t_search:t_end]):

                valid_slice = slice(t_search, t_end)

                time_mask = mask[valid_slice]

                curr_mp = timeline_manpower[valid_slice][time_mask]

                max_mp = np.max(curr_mp) if len(curr_mp) > 0 else 0

                

                res_ok = True

                if task['Is_Offline']:

                    curr_res = offline_resource_usage[res_group][valid_slice][time_mask]

                    max_res = np.max(curr_res) if len(curr_res) > 0 else 0

                    if max_res >= res_limit: res_ok = False

                

                if res_ok and (max_mp + manpower <= total_manpower):

                    return t_search, t_end, this_setup, None

                else:

                    t_search += 5 

            else:

                t_search += 5 

        return None



    def book_slot(task, l_idx, slot_info, log_msg=""):

        start, end, setup, _ = slot_info

        manpower = int(task['Manpower_Req'])

        

        # â˜…â˜…â˜… ä¿®æ­£ 2: æ›ç·šæ™‚é–“é¡¯ç¤º â˜…â˜…â˜…

        # æ’ç¨‹é¡¯ç¤ºçš„é–‹å§‹æ™‚é–“ = å¯¦éš›ä¸Šå·¥æ™‚é–“ = Start + Setup

        # ä½†ç³»çµ±é ç•™æ™‚é–“æ˜¯å¾ Start é–‹å§‹åˆ° End

        # ç‚ºäº†å ±è¡¨æ­£ç¢ºï¼Œé è¨ˆé–‹å§‹æ™‚é–“æ‡‰è©²é¡¯ç¤º Startï¼Œä¸¦è¨»æ˜åŒ…å«æ›ç·š

        # æˆ–è€…ï¼šé è¨ˆé–‹å§‹ = Start (åŒ…å«æ›ç·š)ï¼Œå®Œå·¥æ™‚é–“ = End

        # ä½¿ç”¨è€…è¦æ±‚ï¼šå®Œå·¥æ™‚é–“ 11:46, æ›ç·š 10 åˆ† -> ä¸‹ä¸€å¼µé è¨ˆé–‹å§‹ 11:56

        # æ‰€ä»¥é€™è£¡çš„ Start å·²ç¶“æ˜¯ "åŒ…å«äº†æ›ç·šæ™‚é–“" çš„èµ·é»å—ï¼Ÿ

        # find_earliest_slot å›å‚³çš„ `start` æ˜¯ "èƒ½é–‹å§‹å¡å…¥(å«æ›ç·š)çš„æ™‚é–“é»"

        # æ‰€ä»¥é¡¯ç¤ºä¸Šï¼šé è¨ˆé–‹å§‹ = start + setup

        

        display_start = start + setup

        

        if task['Is_Offline']:

            mask_slice = offline_mask[start:end]

            timeline_manpower[start:end][mask_slice] += manpower

            res_group = task['Process_Category']

            offline_resource_usage[res_group][start:end][mask_slice] += 1

            display_line = res_group

        else:

            mask_slice = line_masks[l_idx][start:end]

            timeline_manpower[start:end][mask_slice] += manpower

            line_usage_matrix[l_idx, start:end] = True

            line_free_time[l_idx] = end

            line_last_model[l_idx] = task['Base_Model']

            display_line = f"Line {l_idx+4}"

            

        order_finish_times[(str(task['Order_ID']), task['Sequence'])] = end

        

        results.append({

            'ç”¢ç·š': display_line,

            'å·¥å–®': task['Order_ID'], 'ç”¢å“': task['Product_ID'], 

            'æ•¸é‡': task['Qty'], 'é¡åˆ¥': 'ç·šå¤–' if task['Is_Offline'] else 'æµæ°´ç·š', 

            'æ›ç·š(åˆ†)': setup, 'éœ€æ±‚äººåŠ›': manpower, 

            'é è¨ˆé–‹å§‹': format_time_str(display_start), # é¡¯ç¤ºå¯¦éš›ç”Ÿç”¢é–‹å§‹æ™‚é–“

            'å®Œå·¥æ™‚é–“': format_time_str(end), 

            'ç·šä½”ç”¨(åˆ†)': (end - start), 'ç‹€æ…‹': 'OK', 'æ’åºç”¨': end,

            'å‚™è¨»': task.get('Remarks', ''), 'æŒ‡å®šç·š': task.get('Line_Col', ''),

            'æ€¥å–®': 'Yes' if task.get('Order_Is_Rush') else '', 'åˆ¤æ–·': log_msg

        })



    def check_dependency(task):

        if task['Sequence'] <= 1: return True, parse_time_to_mins(line_settings[0]["start"])

        prev_key = (str(task['Order_ID']), task['Sequence'] - 1)

        if prev_key in order_finish_times:

            return True, order_finish_times[prev_key]

        return False, 0



    # ==================================================

    # STEP 1 & 2: æ€¥å–®å„ªå…ˆ + å¤šå·¥å–®å¡«è£œ (Multi-Gap Fill)

    # ==================================================

    while pool_rush:

        task = pool_rush.pop(0)

        is_ready, dep_time = check_dependency(task)

        

        if not is_ready:

            pool_rush.append(task)

            # å®‰å…¨æ©Ÿåˆ¶... (çœç•¥ï¼Œèˆ‡ v23 ç›¸åŒ)

            if len(pool_rush) > 0 and all(not check_dependency(t)[0] for t in pool_rush):

                pass

            continue



        if task['Is_Offline']:

            min_start = max(dep_time, parse_time_to_mins(offline_settings["start"]))

            slot = find_earliest_slot(task, -1, min_start)

            if slot: book_slot(task, -1, slot, "Rush_Offline")

        else:

            t_req = task['Target_Line']

            candidates = [t_req-4] if t_req > 0 else [l for l in range(total_lines) if check_line_permission(l, task['Base_Model'], False, 0)]

            

            best_opt = None

            for l_idx in candidates:

                # â˜…â˜…â˜… ä¿®æ­£ 1: å¤šå·¥å–®å¡«è£œè¿´åœˆ (Multi-Fill) â˜…â˜…â˜…

                # åªè¦ç©ºéš™å¤ å¤§ï¼Œå°±ä¸€ç›´å¡«ï¼Œå¡«åˆ°ä¸èƒ½å¡«ç‚ºæ­¢

                while True:

                    gap = dep_time - line_free_time[l_idx]

                    if gap <= 30: break # ç©ºéš™å¤ªå°ï¼Œä¸å¡«äº†ï¼Œç›´æ¥æ’æ€¥å–®

                    

                    # å°‹æ‰¾æœ€ä½³å¡«è£œè€… (Normal Pool)

                    best_filler = None # (idx, task, slot)

                    

                    for n_idx, n_task in enumerate(pool_normal):

                        if n_task['Is_Offline']: continue

                        if not check_line_permission(l_idx, n_task['Base_Model'], False, 0): continue

                        n_ready, n_dep = check_dependency(n_task)

                        if not n_ready: continue

                        

                        # è©¦ç®—

                        n_start = max(line_free_time[l_idx], n_dep)

                        n_slot = find_earliest_slot(n_task, l_idx, n_start)

                        

                        if n_slot:

                            n_end = n_slot[1]

                            # å…è¨±ç¨å¾®å»¶å¾Œ (10%)

                            if n_end <= dep_time + (gap * 0.1):

                                # è²ªå©ªï¼šæ‰¾æ™‚é–“æœ€æ¥è¿‘ gap (å¡æœ€æ»¿) çš„å–®

                                # æˆ–è€…æ‰¾æœ€æ—©èƒ½é–‹å§‹çš„å–®? é€™è£¡é¸ "å¡å¾—æœ€å‰›å¥½" -> æ¸›å°‘å‰©é¤˜ç©ºéš™

                                # ä½†ç‚ºäº†ç°¡å–®ä¸”é«˜æ•ˆï¼Œæˆ‘å€‘é¸ "ç¬¬ä¸€å¼µèƒ½å¡é€²å»çš„" (First Fit) 

                                # æˆ–è€… "è€—æ™‚æœ€é•·ä½†å°æ–¼ gap" çš„ (Best Fit)

                                f_dur = n_end - n_start

                                if best_filler is None or f_dur > (best_filler[2][1] - best_filler[2][0]):

                                    best_filler = (n_idx, n_task, n_slot)

                    

                    if best_filler:

                        f_idx, f_task, f_slot = best_filler

                        book_slot(f_task, l_idx, f_slot, "Rush_Multi_Fill")

                        pool_normal.pop(f_idx)

                        # å¡«è£œå¾Œ line_free_time æ¨é€²äº†ï¼Œè¿´åœˆç¹¼çºŒæª¢æŸ¥å‰©é¤˜ gap

                    else:

                        break # æ‰¾ä¸åˆ°èƒ½å¡«çš„å–®äº†ï¼Œè·³å‡ºå¡«è£œè¿´åœˆ



                # æ­£å¸¸æ’æ€¥å–® (æ­¤æ™‚ gap æ‡‰è©²å·²ç¶“è¢«å¡«åˆ°æœ€å°)

                my_start = max(dep_time, line_free_time[l_idx])

                slot = find_earliest_slot(task, l_idx, my_start)

                if slot:

                    if best_opt is None or slot[1] < best_opt[0]:

                        best_opt = (slot[1], l_idx, slot)

            

            if best_opt:

                book_slot(task, best_opt[1], best_opt[2], "Rush_On")

            else:

                results.append({'å·¥å–®': task['Order_ID'], 'ç‹€æ…‹': 'Fail', 'å‚™è¨»': 'æ€¥å–®è³‡æºä¸è¶³'})



    # ==================================================

    # STEP 3: å›ºå®šç·šå¡æ»¿ (Fixed Line Saturation)

    # ==================================================

    fixed_tasks_map = {} 

    for t in pool_fixed:

        target = -1

        if t['Target_Line'] > 0: target = t['Target_Line'] - 4

        else:

            b = engine.get_product_binding(t['Base_Model'])

            if b is not None: target = b

        

        if target != -1:

            if target not in fixed_tasks_map: fixed_tasks_map[target] = []

            fixed_tasks_map[target].append(t)

            

    for l_idx, tasks in fixed_tasks_map.items():

        tasks.sort(key=lambda x: x['Sequence'])

        for task in tasks:

            is_ready, dep_time = check_dependency(task)

            min_start = max(dep_time, line_free_time[l_idx])

            slot = find_earliest_slot(task, l_idx, min_start)

            if slot: book_slot(task, l_idx, slot, "Fixed_Saturation")

            else: results.append({'å·¥å–®': task['Order_ID'], 'ç‹€æ…‹': 'Fail', 'å‚™è¨»': 'å›ºå®šç·šè³‡æºä¸è¶³'})



    # ==================================================

    # STEP 4: ä¸€èˆ¬å·¥å–®è²ªå©ªå¡«å…… (Normal Greedy)

    # ==================================================

    while pool_normal:

        lines_status = sorted(range(total_lines), key=lambda x: line_free_time[x])

        global_best = None 

        

        for l_idx in lines_status:

            line_ready_time = line_free_time[l_idx]

            if global_best and line_ready_time > global_best[1] + 1440: continue



            for t_idx, task in enumerate(pool_normal):

                if task['Is_Offline']: continue 

                if not check_line_permission(l_idx, task['Base_Model'], task['Target_Line']>0, task['Target_Line']): continue

                

                is_ready, dep_time = check_dependency(task)

                if not is_ready: continue

                

                start_time = max(line_ready_time, dep_time)

                gap = start_time - line_ready_time

                if gap > 2880: continue 

                

                slot = find_earliest_slot(task, l_idx, start_time)

                if slot:

                    finish = slot[1]

                    setup = slot[2]

                    score = (gap * 100) + finish + (setup * 5)

                    if global_best is None or score < global_best[0]:

                        global_best = (score, finish, l_idx, t_idx, slot)

            

            if global_best and (global_best[4][0] - line_ready_time == 0) and global_best[4][2] == 0:

                break



        # ç·šå¤–

        for t_idx, task in enumerate(pool_normal):

            if not task['Is_Offline']: continue

            is_ready, dep_time = check_dependency(task)

            if not is_ready: continue

            

            min_start = max(dep_time, parse_time_to_mins(offline_settings["start"]))

            slot = find_earliest_slot(task, -1, min_start)

            if slot:

                finish = slot[1]

                if global_best is None or slot[0] < global_best[0]: 

                    global_best = (slot[0], finish, -1, t_idx, slot)



        if global_best:

            _, _, l_idx, t_idx, slot = global_best

            book_slot(pool_normal[t_idx], l_idx, slot, "Normal_Greedy")

            pool_normal.pop(t_idx)

        else:

            if all(not check_dependency(t)[0] for t in pool_normal):

                for t in pool_normal: results.append({'å·¥å–®': t['Order_ID'], 'ç‹€æ…‹': 'Fail', 'å‚™è¨»': 'æ­»é–'})

                break

            if pool_normal:

                for t in pool_normal: results.append({'å·¥å–®': t['Order_ID'], 'ç‹€æ…‹': 'Fail', 'å‚™è¨»': 'è³‡æºä¸è¶³'})

                break



    if results:

        last = max([r['æ’åºç”¨'] for r in results if r.get('ç‹€æ…‹')=='OK'], default=0)

        days = (last // 1440) + 1

        df_res = pd.DataFrame(results)

        df_eff = calculate_daily_efficiency(timeline_manpower, line_masks, total_manpower, results, days)

        df_util = calculate_line_utilization(line_usage_matrix, line_masks, total_lines, days)

        df_idle = analyze_idle_manpower(timeline_manpower, line_masks, total_manpower, days*1440)

        return df_res, df_idle, df_eff, df_util

        

    return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()



# ==========================================

# 6. UI

# ==========================================

st.set_page_config(page_title="AI æ™ºèƒ½æ’ç¨‹ç³»çµ±", layout="wide")

st.title(f"ğŸ­ {SYSTEM_VERSION}")



with st.sidebar:

    st.header("âš™ï¸ å…¨åŸŸåƒæ•¸")

    total_manpower = st.number_input("å…¨å» ç¸½äººåŠ›", value=50)

    total_lines = st.number_input("ç”¢ç·šæ•¸é‡", value=5)

    c1, c2 = st.columns(2)

    std_changeover = c1.number_input("æ¨™æº–æ›ç·š", value=10)

    sim_changeover = c2.number_input("ç›¸ä¼¼æ›ç·š", value=5)

    

    line_settings = []

    with st.expander("ç”¢ç·šæ™‚é–“", expanded=True):

        for i in range(total_lines):

            c1, c2 = st.columns(2)

            s = c1.time_input(f"L{i+4}èµ·", time(8,0), key=f"s{i}")

            e = c2.time_input(f"L{i+4}è¿„", time(17,0), key=f"e{i}")

            line_settings.append({"start": s.strftime("%H:%M"), "end": e.strftime("%H:%M")})

    

    c1, c2 = st.columns(2)

    os = c1.time_input("ç·šå¤–èµ·", time(8,0))

    oe = c2.time_input("ç·šå¤–è¿„", time(17,0))

    offline_settings = {"start": os.strftime("%H:%M"), "end": oe.strftime("%H:%M")}



f = st.file_uploader("ä¸Šå‚³ Excel (å«å·¥å–®èˆ‡è¦å‰‡)", type=['xlsx'])

if f:

    df, engine, err = load_and_clean_data(f)

    if err: st.error(err)

    else:

        with st.expander("è¦å‰‡æª¢è¦–"):

            st.write("Fixed:", engine.fixed_lines)

            st.write("Product Binding:", engine.product_binding)

            

        if st.button("Run"):

            res, idle, eff, util = run_scheduler(df, engine, total_manpower, total_lines, std_changeover, sim_changeover, line_settings, offline_settings)

            

            t1, t2, t3, t4 = st.tabs(["æ’ç¨‹è¡¨", "æ•ˆç‡", "ç¨¼å‹•", "é–’ç½®"])

            with t1: st.dataframe(res, use_container_width=True)

            with t2: st.dataframe(eff, use_container_width=True)

            with t3: st.dataframe(util, use_container_width=True)

            with t4: st.dataframe(idle, use_container_width=True)



            out = io.BytesIO()

            with pd.ExcelWriter(out, engine='xlsxwriter') as writer:

                res.to_excel(writer, sheet_name="æ’ç¨‹", index=False)

                eff.to_excel(writer, sheet_name="æ•ˆç‡", index=False)

                util.to_excel(writer, sheet_name="ç¨¼å‹•", index=False)

                idle.to_excel(writer, sheet_name="é–’ç½®", index=False)

            out.seek(0)

            st.download_button("ä¸‹è¼‰å ±è¡¨", out, "Schedule_v23.1.xlsx")
